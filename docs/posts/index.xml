<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>数値実験部屋</title>
    <link>https://kitano-AppMath.github.io/kitano_blog/posts/</link>
    <description>Recent content on 数値実験部屋</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <lastBuildDate>Sun, 04 Jun 2023 09:59:15 +0900</lastBuildDate><atom:link href="https://kitano-AppMath.github.io/kitano_blog/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2023 06 04</title>
      <link>https://kitano-AppMath.github.io/kitano_blog/posts/2023-06-04/</link>
      <pubDate>Sun, 04 Jun 2023 09:59:15 +0900</pubDate>
      
      <guid>https://kitano-AppMath.github.io/kitano_blog/posts/2023-06-04/</guid>
      <description> 目次 はじめに 経緯と概要 Metropolis-Hastings法を利用するメリット Metropolis-Hastings法のアルゴリズム MCMCの考え方 MCMCの基礎 Markov連鎖の基礎 詳細釣り合い条件 Metropolis-Hastings法 Metropolis-Hastings法の歴史 遷移核の決定 採択／棄却確率 提案分布の選び方 数値実験 はじめに 経緯と概要 Metropolis-Hastings法を利用するメリット Metropolis-Hastings法のアルゴリズム MCMCの考え方 MCMCの基礎 Markov連鎖の基礎 詳細釣り合い条件 Metropolis-Hastings法 Metropolis-Hastings法の歴史 遷移核の決定 採択／棄却確率 提案分布の選び方 数値実験 </description>
    </item>
    
    <item>
      <title>missing fundamental</title>
      <link>https://kitano-AppMath.github.io/kitano_blog/posts/2023-06-03/</link>
      <pubDate>Sat, 03 Jun 2023 02:39:10 +0900</pubDate>
      
      <guid>https://kitano-AppMath.github.io/kitano_blog/posts/2023-06-03/</guid>
      <description>目次 missing fundamental 音響信号処理の基礎知識 音波の基礎知識 基音と倍音 ピッチ 改めて，missing fundamentalとは 数値実験 missing fundamental missing fundamentalとは，基音と倍音から構成される音から基音を取り除いた倍音列を聴いても，人間は元の音と同じピッチを知覚する 現象のことである．このままではよく分からないので，一つずつ紐解いていこう．実験に使ったJuliaプログラムはこちら．
音響信号処理の基礎知識 音響工学の教科書1を参考に，音響信号処理の用語をいくつか整理しておこう．
音波の基礎知識 音とは，空気中や水中を伝搬する振動のことである．また，物理的な現象としての音が引き起こす（人間の）聴覚的感覚も音と呼ばれる．missing fundamentalは人間の知覚に関する現象であり，この記事では両方の「音」を扱う．物理現象としての音を記述する物理量として振幅や周波数，音圧が代表的である．この記事では，周波数と，音の高さの感覚であるピッチについて軽く触れる．
基音と倍音 普通，音は複数の周波数成分から構成される．ここで，周波数とは，単位時間あたりの波の数を指す．この複数の周波数成分のうち，最も低い周波数成分は基音と呼ばれる．また，基音の周波数の整数倍 の周波数のうち，ただ１つを成分として持つ音を倍音と呼ぶ．例えば，200Hzの音を基音とするとき，600Hzや1000Hzの音は，いずれもその倍音である．
ピッチ 音の高さの感覚 をピッチと呼ぶ．ピッチはおおよそ周波数で決まり，その間の関係はメル尺度によって記述される．要するに，周波数が大きいほど，その音は高いと知覚されるということだ．
改めて，missing fundamentalとは 改めて，missing fundamentalについて考えてみよう．いま，ある基音とその倍音から構成される音が発生したとする．人間はこの音を知覚するとき，ピッチにより音の高さを感じる．いま，発せられた音から基音を取り除いてみよう．基音を除く倍音のみからなる音を人間が聞くとどうなるだろうか．普通は低周波数成分が消えるのだから，元の音より高く聞こえるだろう．しかし，人間は元の音と同じくらいの高さを感じてしまう ．この現象をmissing fundamentalと呼ぶ．言い換えれば，我々は，残った周波数成分の最大公約数の周波数成分を勝手に補ってしまうということだ．
数値実験 Juliaを使って音響信号を作成し，実験を行った．200Hz，1000Hz，1200Hz，1400Hz，1600Hzを合成した音を以下で再生できる．
【オリジナルの音（音量注意！！）】
この音から，基音200Hzを取り除いた音を以下で再生できる．
【基音を取り除いた音（音量注意！！）】
確かに，低周波成分が残っているように聞こえる&amp;hellip;
飯田 一博. 音響工学基礎論. コロナ社, 2012.&amp;#160;&amp;#x21a9;&amp;#xfe0e;</description>
    </item>
    
    <item>
      <title>共役勾配法</title>
      <link>https://kitano-AppMath.github.io/kitano_blog/posts/2023-02-19/</link>
      <pubDate>Sun, 19 Feb 2023 23:38:01 +0900</pubDate>
      
      <guid>https://kitano-AppMath.github.io/kitano_blog/posts/2023-02-19/</guid>
      <description>目次 共役勾配法の概要 経緯と概要 共役勾配法を利用するメリット 共役勾配法のアルゴリズム ２つのストーリー 共役勾配法を構成する 解の特徴づけ 直交化 共役勾配法を俯瞰する Krylov部分空間法 共役勾配法の位置づけ 数値実験 例１：密行列の場合 例２：疎行列の場合 共役勾配法の概要 経緯と概要 共役勾配法（conjugate gradeint method）はHestenesとStiefel1によって提案された連立一次方程式の数値解法で，CG法とも呼ばれる．発表当初から大々的に報道されたようで，&amp;ldquo;数値計算法の一解法が, これほど大々的に報道されたことは, 前にも後にも例がない&amp;quot;との記述も2．1980年代にはKrylov部分空間法として再定式化されたことでも有名．ちなみにKrylov部分空間法は20世紀のトップ10アルゴリズムの１つである．この記事では，共役勾配法はどこから来たのか，何がすごいのか，そして，Krylov部分空間法とは何者か簡単に説明する．実験に使ったJuliaプログラムはこちら．
共役勾配法を利用するメリット 共役勾配法はなぜこれほどまで注目されたのだろうか．この解法の特に優れた点を以下に挙げてみよう．
原理的には ，有限回の反復で厳密解に収束する 行列の全成分を知らなくても, 行列-ベクトル積が分かれば アルゴリズム自体は動く fill inを回避できる（＝行列の疎性が壊れない） １点目に関して補足すると，理論上は$n\times n$の係数行列に対して$n$回の反復で収束するが，実際の計算では丸め誤差の影響で，収束により多くの反復を要する ことがある．２点目に関しては，極論，係数行列の中身が分からなくても良い．とにかくベクトル行列式を計算する関数さえ定義できれば良いのだ．３点目に関して，fill inとは，係数行列の零成分が反復の途中で非零になる現象を指す．非零になった分メモリを確保する必要があり，余計にコストがかかるため，fill inは嬉しくない現象である．まあとにかく，共役勾配法を使わない手はない！（Juliaのデフォルトのソルバーは優秀なので自分でコードを組むことは少ないかもしれない．なお，共役勾配法を含むKrylob部分空間法を基にした数値解法を実装したパッケージは充実している模様．）
共役勾配法のアルゴリズム 詳細に入る前に，共役勾配法のアルゴリズムを示しておこう．
定義（共役勾配法） 共役勾配法とは，$n$次正方行列$A$，$n$次元ベクトル$b$に対して，連立一次方程式$Ax=b$の近似解列$\left\{ x_n \right\}_{n=0}^{\infty}$を次のように生成する方法を指す．
Initialize $x_0$, and set $r_0=b-Ax_0$ and $p_0=r_0$. for $k=0, 1, \dots$ do
&amp;emsp;Update $\alpha_k = \frac{r_{k}^\top p_k}{p_k^{\top} Ap_k}$. &amp;emsp;Update $x_{k+1} = x_k + \alpha_k p_k$. &amp;emsp;Update $r_{k+1} = b - Ax_{k+1}$.</description>
    </item>
    
    <item>
      <title>Gershgorinの定理</title>
      <link>https://kitano-AppMath.github.io/kitano_blog/posts/2023-02-18/</link>
      <pubDate>Sat, 18 Feb 2023 00:21:07 +0900</pubDate>
      
      <guid>https://kitano-AppMath.github.io/kitano_blog/posts/2023-02-18/</guid>
      <description>目次 定理の概要と例 概要 定理の内容 例１：単純な例 例２：相似変換 例３：狭義優対角行列 定理の概要と例 概要 Gershgorinの定理1は，行列の固有値のおおよその存在範囲を教えてくれる，ありがたい定理である．この定理だけで一冊の本2になるほどご利益がある．応用としては，数値解析をはじめ，グラフ理論などにも利用される．主張自体は数値解析の書籍3に書いてあることが多いが，ここではN. Highamのブログ記事4を参考にして，いくつか例を調べてみよう．実験に使ったJuliaプログラムはこちら．
定理の内容 定理のstatementは以下の通りだ．
定理（Gershgorinの定理） 複素正方行列$A=(a_{ij})\in\mathbb{C}^{n\times n}$と，その任意の固有値$\lambda$に対して，次式が成り立つ： \begin{equation} \lambda \in \bigcup_{i=1}^{n}\left\{ z\in\mathbb{C} \mid |z-a_{ii}| \leq \sum_{j\neq i}{|a_{ij}|} \right\}. \end{equation} つまり，任意の固有値の存在範囲が閉円盤の和集合に限定される ことを主張している．しかも存在範囲は行列の成分からすぐに分かる．ここで注意点だが，固有値を含む円盤が存在することを主張しているだけで，当然，固有値を含まない円盤が存在する可能性もある ．しかし，実は，上の定理の精密化5が存在して，固有値を含まない円盤が他の円盤と独立して存在する可能性は排除される．つまり，固有値を含まない円盤は，固有値を含む他の円盤と必ず繋がっている．まあ，とりあえず例を見てみよう．
例１：単純な例 適当に行列を作って試してみよう．今回使った行列は \begin{equation} A_1 = \begin{bmatrix} 1&amp;0&amp;1+i&amp;1&amp;0\\ -1&amp;-1&amp;0&amp;-1&amp;0\\ 2&amp;1&amp;1&amp;-1&amp;0\\ 0&amp;2&amp;1&amp;1&amp;0\\ 2&amp;0&amp;1&amp;0&amp;1 \end{bmatrix}. \end{equation} 下図の赤い円が円盤の境界，黒点が固有値である．
例２：相似変換 行列の相似変換により固有値は変わらないが，当然，円盤は変わる．Gershgorinの定理の観点から，対角化などの相似変換について考えてみよう．行列の対角化ができるならば，非対角成分が零になるから，円盤の半径も零になる．つまり，円盤は固有値の点に潰れるわけだ．Gershgorinの定理が固有値の存在範囲に関する情報を与えることを考えると，対角化のようなコストのかかる変換により固有値の存在範囲が絞られるのは自然なことである．同様に考えれば，仮に対角化まではできなくても，対角化に準ずる変換により固有値の存在範囲を絞る ことができると考えられる．ここでは上三角化を考えてみよう．
次のような行列を考えよう： \begin{equation} A_2 = \begin{bmatrix} -1&amp;1&amp;0\\ 1&amp;3&amp;1\\ 1&amp;-3&amp;0 \end{bmatrix}. \end{equation} このとき，正則行列 \begin{equation} P_2 = \begin{bmatrix} 1&amp;0&amp;0\\ 0&amp;1&amp;0\\ -1&amp;-2&amp;1\end{bmatrix} \end{equation} により， \begin{equation} \Lambda_2 = P_2^{-1}A_2P_2 = \begin{bmatrix} -1&amp;1&amp;0\\0&amp;1&amp;1\\0&amp;0&amp;2\end{bmatrix} \end{equation} と上三角化できる．円盤が小さくなったか確認してみよう．左下図は元の行列$A_2$，右下図はその上三角化$\Lambda_2$である．確かに固有値の存在範囲がより狭くなっている．</description>
    </item>
    
    <item>
      <title>Arnoldの猫写像</title>
      <link>https://kitano-AppMath.github.io/kitano_blog/posts/2023-02-14/</link>
      <pubDate>Tue, 14 Feb 2023 11:12:15 +0900</pubDate>
      
      <guid>https://kitano-AppMath.github.io/kitano_blog/posts/2023-02-14/</guid>
      <description>目次 定義とお絵描き 概要 定義 サメの絵で実験 定義とお絵描き Arnoldの猫写像を定義して，かる〜く実験する．画像さえあれば実験できるので，やってみてね．
概要 Arnoldの猫写像とは，Arnoldが作った，2次元から2次元への&amp;quot;chaotic&amp;quot;な写像である．そして入力の画像にはなぜか猫のイラストが使われる．応用としては，カオスベースの画像暗号化技術などが挙げられる1．後ほど見るように，この写像には周期がある．暗号化など，セキュリティ分野への応用を考えれば，周期の研究に関心が向くのは自然だろう．どうやらDyson and Folk2の研究が代表的らしい．Bao and Yang1でも周期に関する公式が導出されている．Fibonacci数列との関連も興味深いが，この記事ではネット上の講義資料3を参考にいくつか実験してみよう．実験に使ったJuliaプログラムはこちら．
定義 定義（Arnoldの猫写像） 自然数$N$に対して，Arnoldの猫写像とは，次式で定まる写像$F\colon\mathbb{R}^2\to\mathbb{R}^2$を指す： \begin{equation} F\left(\begin{bmatrix} x \\ y \end{bmatrix}\right) = \begin{bmatrix} 1 &amp; 1 \\ 1 &amp; 2 \end{bmatrix}\begin{bmatrix} x \\ y \end{bmatrix} \quad \pmod N. \end{equation} また，冒頭に述べた周期も定義しておこう．
定義 （周期） 自然数$N$とArnoldの猫写像$F$に対して， \begin{equation} T = \min\left\{ k\in\mathbb{N} \mid \text{任意の点$p$に対して，}F^k(p) = p \right\} \end{equation} を周期という．
サメの絵で実験 次のような画像で実験してみよう．
この画像に猫写像を何度か作用させるのだ．一旦はぐちゃぐちゃになるんだが，何度か作用させると元に戻る．このとき，作用させた回数が周期だ．まあ，とりあえずやってみよう．$15$回ほど反復させた図を下図に示した．
画像サイズ$N$に対して周期がどのように変化するか調べてみよう．周期に関してはいくつか式が知られているが，ここではコンピュータの力を借りて愚直に調べる．画像サイズ$N$を変化させるごとに，猫写像を何度も作用させ，画像が一致するまで繰り返す．下図の横軸が$N$，縦軸が周期である．傾向として，$N$が大きくなるに従って周期も大きくなる．また，なんとなく規則性もありそう...
J. Bao and Q. Yang. Period of the discrete Arnold cat map and general cat map, Nonlinear Dynamics, 70(2012), pp.</description>
    </item>
    
    <item>
      <title>変分推論法</title>
      <link>https://kitano-AppMath.github.io/kitano_blog/posts/2023-02-11/</link>
      <pubDate>Fri, 10 Feb 2023 16:44:19 +0900</pubDate>
      
      <guid>https://kitano-AppMath.github.io/kitano_blog/posts/2023-02-11/</guid>
      <description>目次 変分推論法の概要 導入 問題設定 基本的な考え方 経験Bayes法との組み合わせ 平均場近似による方法 方針 例１：単純な例 勾配計算による方法 方針 例２：ロジスティック回帰 変分推論法の概要 ここでは，変分推論法の基本となる考え方を紹介する．
導入 変分推論法とは，主にBayes推定において，複雑な事後分布を，より単純な分布で近似する最適化ベースの学習方法 を指す．具体的にどのような分布で近似するかは後に回して，ここでは，どのように近似するかを述べ，最適化問題として定式化しておこう．変分推論法の包括的な説明としては，Bealの博士論文1やBleiのレビュー論文2が参考になりそう．この記事の実験で使ったJuliaプログラムはこちら．
問題設定 いま，手元には$N$次元データからなる有限集合$\mathcal{D}$があるとしよう．統計家は，データ点$x_1, \dots, x_{\#\mathcal{D}}\in\mathcal{D}$を，未知の真の分布$\mathcal{Q}$に従う独立な確率変数列$X_1, \dots, X_{\#\mathcal{D}}$の一組の実現値であると想定し，真の分布を推測するための確率モデル$\mathcal{P}_\theta$を作る．そして，予測分布$\mathcal{P}^* $を計算し，真の分布$\mathcal{Q}$はおおよそ${\mathcal{P}}^* $であろうと推測する．ただし，$\theta\in\Theta$は未知のパラメータであり，データと確率モデルから推定する必要がある．Bayes推定を用いる場合には，確率モデル$p(\cdot\mid\theta)$と，既知のパラメータ$\lambda\in\Lambda$を持つ事前分布$\pi_{\lambda}$を作り，次式で定義される事後分布を計算する： \begin{equation} \pi^*_{\lambda} (\theta\mid\mathcal{D}) = \frac{1}{\mathcal{M}_\lambda}\left[\prod_{x\in\mathcal{D}}p(x\mid\theta)\right]\pi_{\lambda}(\theta). \end{equation} ただし，$\mathcal{M}_{\lambda}$は周辺尤度と呼ばれ， \begin{equation} \mathcal{M}_{\lambda} = \int \left[\prod_{x\in\mathcal{D}}p(x\mid\theta)\right]\pi_{\lambda}(\theta)\mathrm{d}{\theta} \end{equation} で定義される．この事後分布に対して，（Bayes事後）予測分布を \begin{equation} {p_{\lambda}}^* (x) = \int p(x\mid\theta)\pi_{\lambda}^*(\theta\mid\mathcal{D})\mathrm{d}\theta \end{equation} と定義する．この記事では，事後分布の解析的な計算が難しい場合を考えよう．
基本的な考え方 さて，冒頭で述べたように，変分推論法では事後分布を近似する．近似事後分布の族を$\mathcal{R}$とし，近似事後分布と事後分布との近さをKullback-Leiblerダイバージェンス \begin{equation} D_{\mathrm{KL}}[r \Vert \pi_{\lambda}^* ] = \int\log\left[\frac{r(\theta\mid\mathcal{D})}{\pi_{\lambda}^* (\theta\mid\mathcal{D})}\right]r(\theta\mid\mathcal{D})\mathrm{d}\theta, \quad r(\theta\mid\mathcal{D})\in\mathcal{R} \end{equation} で測ろう．これを最小化できると良いのだが，事後分布に周辺尤度の計算を含むため，次のような量を定義する： \begin{equation} \mathcal{L}_{\lambda}[r] = -D_{\mathrm{KL}}[r \Vert \pi_{\lambda}^* ] + \log \mathcal{M}_{\lambda}.</description>
    </item>
    
  </channel>
</rss>
